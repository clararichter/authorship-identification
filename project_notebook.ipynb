{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dating Documents\n",
    "\n",
    "1) Prediction you hope to make\n",
    "\n",
    "Given a short text in English, we wish to perform a classification in predicting the year (or the decade in which) it was written. The writing style of a written work from, say the 1800s, is certainly very different from that of a modern text, and we hope to build a model that can recognize this difference in a consistent way. The related, but different, problem of \"author identification\" has been tackled before (e.g. see [1] and [2]). \n",
    "\n",
    "2) Data sources\n",
    "- http://www.gutenberg.org/\n",
    "- https://books.google.com/ngrams\n",
    "- https://googlebooks.byu.edu/x.asp (more advanced word tool)\n",
    "- Google Books (for retrieving publishing dates)\n",
    "\n",
    "3) Data cleaning plan - what will you need to do to make the data usable? Include tables showing where data issues are.\n",
    "\n",
    "Given a written work that can be accessed from gutenberg.org, we wish to obtain a dataset which captures word frequency. NLTK makes this process very simple. Using the \"FreqDist\" class, we can produce a list with all words and the number of times they appear in the form of a list of tuples: [(<word>, <word count>), ...]. Any\n",
    "We only include actual words, i.e. not punctuations etc.\n",
    "   \n",
    "Here are a couple of concerns that came up regarding how we should clean and interpret the data:\n",
    "\n",
    "Concerns/questions/ideas:\n",
    "\n",
    "1) Do we want all genres of written documents, or just e.g. fictional writing?\n",
    "\n",
    "2) Stemmatizing/lemmatizing words? \n",
    "\n",
    "3) Should we distinguish between lower and uppercase words, or not? Initally we thought it would be a good this to make the set of words uniform in terms of case: consider the case where a word is the first of a sentence and thus have the first of its letter capitalized versus when it does not and have all letters lowercase. In terms of frequency, we'd like to count them as the same word. On the other hand, when it comes to names, we do want to keep the capitalization. It turns out that Google n-grams is case-sensitive. So we definitely want our dataset to be so as well. It really depends on the importance the frequency metric will have for our model. Perhaps we only care about the fact that a word <i> occurs </i> in our dataset, and not its frequency.\n",
    "\n",
    "4) do we analyze the entirety of the written work, or smaller paragraphs of it? If the paragraphs are too short, this potentially diminishes the informativeness of word frequency; if a paragraph consists of 500 words and 2/3 of these are generic words such as \"and\", \"if\" and \"but\", then perhaps too little room is left for epoch-characteristic words. \n",
    "\n",
    "5) Google n-grams \"charts the frequencies of any set of comma-delimited search strings using a yearly count of n-grams found in sources printed between 1500 and 2008 in Google's text corpora\". However, the frequency for any given year should depend on <i> the number of works that were published in that given year </i>. It most likely is the case that fewer works from the 1500s are incorporated in Google's text corpora than those of the 2000's. So the question is whether Google n-grams really capture the <i> relative commonness </i> of a word between time periods? UPDATE: upon closer inspection, Google n-grams actually measures the <i> relative </i> frequency of a given word for the set of works within given time period.\n",
    "   \n",
    " \n",
    " \n",
    "\n",
    "4) Data exploration/visualization\n",
    "\n",
    "\n",
    "[1] https://web.stanford.edu/class/cs224n/reports/2760185.pdf\n",
    "[2] https://brage.bibsys.no/xmlui/bitstream/handle/11250/2353615/12344_FULLTEXT.pdf?sequence=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
